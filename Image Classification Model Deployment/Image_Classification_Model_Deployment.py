# -*- coding: utf-8 -*-
"""Proyek_Akhir_Pengembangan ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WqosbTwPSIGwrxbPtPcZvmi7ovJL756B

# **Google Image Classification**
*   Nama: Muhammad Hafiz
*   Email: mhdhfz391@gmail.com
*   Id Dicoding: mhdhfzz

**Menyiapkan semua library yang dibutuhkan**
"""

import pandas as pd
import numpy as np
import zipfile
import os
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.applications.densenet import DenseNet201,preprocess_input
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten,Conv2D,MaxPooling2D,Dense,Lambda
from tensorflow.keras.preprocessing.image import load_img,img_to_array
from tensorflow.keras.utils import get_file

from google.colab import drive
from google.colab import files
import pathlib

"""**Install TF nighlty**"""

! pip install -q tf-nightly

"""**API Kaggle dan Download Dataset**"""

! pip install kaggle

drive.mount('/content/gdrive')

os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Kaggle"

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/

!kaggle datasets download -d duttadebadri/image-classification

"""**Ekstrak File zip**"""

local_zip = '/content/image-classification.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content/')
zip_ref.close()

"""**Data Directories**"""

img_dir = '/content/images/images'
val_dir = '/content/validation/validation'
test_dir = '/content/test/test'

"""**image size and batch size**"""

# change as you want
image_size = 256
batch_size = 32

"""**training data**"""

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    directory=img_dir,
    validation_split=0.2,
    subset="training",
    seed=1007,
    image_size=(image_size,image_size),
    batch_size=batch_size,
    label_mode='categorical'
)

class_names=train_ds.class_names
class_names

"""**validation data**"""

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    directory=img_dir,
    validation_split=0.2,
    subset="validation",
    seed=1007,
    image_size=(image_size,image_size),
    batch_size=batch_size,
    label_mode='categorical'
)

"""**test data**"""

test_ds = tf.keras.preprocessing.image_dataset_from_directory(
    directory=test_dir,
    image_size=(image_size,image_size),
    batch_size=batch_size,
    label_mode='categorical',
)

"""**memvisualisasikan (plot) beberapa gambar dari data pelatihan dengan labelnya**"""

# x_shape = []
# y_shape = []
plt.figure(figsize=(12,15))
for img,label in train_ds.take(1):
    for i in range(16):
#         x_shape.append(img[i].shape[0])
#         y_shape.append(img[i].shape[1])
        ax = plt.subplot(4,4,i+1)
        plt.imshow(img[i].numpy().astype("uint8"))
        plt.title(class_names[np.argmax(label[i])])

"""**Your model**"""

base_model = DenseNet201(weights = 'imagenet',
                        include_top = False,
                        input_shape=(image_size,image_size,3))
base_model.trainable = False

model = Sequential()
model.add(Lambda(preprocess_input,input_shape = (image_size,image_size,3)))
model.add(base_model)
model.add(Conv2D(32, 3, padding='same', activation='relu'))
model.add(MaxPooling2D())
model.add(Conv2D(64, 3, padding='same', activation='relu'))
model.add(MaxPooling2D())
model.add(Flatten())
model.add(Dense(64,activation = 'relu'))
model.add(Dense(32,activation = 'relu'))
model.add(Dense(4,activation = 'softmax'))

model.compile(optimizer='adam',loss = 'CategoricalCrossentropy',metrics=['accuracy'])
model.summary()

class stop(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.97 and logs.get('val_accuracy')>0.965):
      self.model.stop_training=True
      print("\n akurasi dari training set dan validation set telah terpenuhi > 97%!")
callbacks=stop()

epochs = 50
history = model.fit(train_ds,validation_data=val_ds,epochs = epochs , batch_size=32,callbacks=[callbacks])

"""**plot error dan accuracy (train dan validation)**"""

history = pd.DataFrame(model.history.history)
history.plot()

"""**Menyimpan model**"""

# Menyimpan model dalam format SavedModel
export_dir = '/gdrive/My Drive/Kaggle/saved_model/'
tf.saved_model.save(model, export_dir)

# Convert SavedModel menjadi vegs.tflite
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('vegs.tflite')
tflite_model_file.write_bytes(tflite_model)

"""**test beberapa gambar dari**
../input/image-classification/test/test/classify
"""

prediction = np.argmax(model.predict(test_ds), axis=-1)
prediction

predictions = []
for i in prediction:
    predictions.append(class_names[i])

plt.figure(figsize=(12,15))
for image,label  in test_ds.take(1):
        for i in range(9):
            plt.subplot(3,3,i+1)
            plt.imshow(image[i].numpy().astype("uint8"))
            plt.title(predictions[i])